{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #then these two lines force keras to use your CPU\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = 'true'\n",
    "#  tensorflow.keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data needs to be preprocessed and split into train and test\n",
    "def array_to_color(array, cmap=\"Oranges\"):\n",
    "    s_m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    return s_m.to_rgba(array)[:,:-1]\n",
    "\n",
    "\n",
    "def rgb_data_transform(data):\n",
    "    data_t = []\n",
    "    for i in range(data.shape[0]):\n",
    "        data_t.append(array_to_color(data[i]).reshape(16, 16, 16, 3))\n",
    "    return np.asarray(data_t, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./full_dataset_vectors.h5\", \"r\") as hf:    \n",
    "\n",
    "    # Split the data into training/test features/targets\n",
    "    X_train = hf[\"X_train\"][:]\n",
    "    targets_train = hf[\"y_train\"][:]\n",
    "    X_test = hf[\"X_test\"][:] \n",
    "    targets_test = hf[\"y_test\"][:]\n",
    "\n",
    "    # Determine sample shape\n",
    "    sample_shape = (16, 16, 16, 3)\n",
    "\n",
    "    # Reshape data into 3D format\n",
    "    X_train = rgb_data_transform(X_train)\n",
    "    X_test = rgb_data_transform(X_test)\n",
    "\n",
    "    # Convert target vectors to categorical targets\n",
    "    targets_train = to_categorical(targets_train).astype(np.integer)\n",
    "    targets_test = to_categorical(targets_test).astype(np.integer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 14, 14, 14, 32)    2624      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 7, 7, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 7, 7, 7, 32)       128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 5, 5, 5, 64)       55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 2, 2, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 2, 2, 64)       256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 258,058\n",
      "Trainable params: 257,866\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/40\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 2.2663 - accuracy: 0.2567 - val_loss: 2.4879 - val_accuracy: 0.1447\n",
      "Epoch 2/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 1.6813 - accuracy: 0.4197 - val_loss: 1.8280 - val_accuracy: 0.3880\n",
      "Epoch 3/40\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 1.4684 - accuracy: 0.4911 - val_loss: 2.3300 - val_accuracy: 0.2940\n",
      "Epoch 4/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.3524 - accuracy: 0.5203 - val_loss: 3.1011 - val_accuracy: 0.2373\n",
      "Epoch 5/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 1.2949 - accuracy: 0.5390 - val_loss: 2.3187 - val_accuracy: 0.3560\n",
      "Epoch 6/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.2303 - accuracy: 0.5617 - val_loss: 2.7701 - val_accuracy: 0.2727\n",
      "Epoch 7/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.1846 - accuracy: 0.5794 - val_loss: 2.5213 - val_accuracy: 0.3320\n",
      "Epoch 8/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.1530 - accuracy: 0.5933 - val_loss: 2.0067 - val_accuracy: 0.4320\n",
      "Epoch 9/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.1196 - accuracy: 0.5960 - val_loss: 1.7270 - val_accuracy: 0.4647\n",
      "Epoch 10/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.0760 - accuracy: 0.6191 - val_loss: 2.2014 - val_accuracy: 0.3853\n",
      "Epoch 11/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 1.0424 - accuracy: 0.6310 - val_loss: 1.4283 - val_accuracy: 0.5137\n",
      "Epoch 12/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 1.0366 - accuracy: 0.6267 - val_loss: 2.0048 - val_accuracy: 0.4267\n",
      "Epoch 13/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 1.0141 - accuracy: 0.6381 - val_loss: 1.6553 - val_accuracy: 0.5027\n",
      "Epoch 14/40\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.9770 - accuracy: 0.6599 - val_loss: 1.1711 - val_accuracy: 0.6187\n",
      "Epoch 15/40\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.9547 - accuracy: 0.6590 - val_loss: 1.3289 - val_accuracy: 0.5560\n",
      "Epoch 16/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.9439 - accuracy: 0.6659 - val_loss: 1.1387 - val_accuracy: 0.6140\n",
      "Epoch 17/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.9310 - accuracy: 0.6751 - val_loss: 2.2869 - val_accuracy: 0.4073\n",
      "Epoch 18/40\n",
      "7000/7000 [==============================] - 32s 5ms/sample - loss: 0.9033 - accuracy: 0.6761 - val_loss: 1.9191 - val_accuracy: 0.4857\n",
      "Epoch 19/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.8927 - accuracy: 0.6830 - val_loss: 1.1475 - val_accuracy: 0.6240\n",
      "Epoch 20/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.8672 - accuracy: 0.6966 - val_loss: 1.3060 - val_accuracy: 0.5613\n",
      "Epoch 21/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.8588 - accuracy: 0.6941 - val_loss: 0.9762 - val_accuracy: 0.6720\n",
      "Epoch 22/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.8409 - accuracy: 0.7011 - val_loss: 1.6559 - val_accuracy: 0.5090\n",
      "Epoch 23/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.8154 - accuracy: 0.7094 - val_loss: 1.2364 - val_accuracy: 0.5950\n",
      "Epoch 24/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.8052 - accuracy: 0.7203 - val_loss: 1.6394 - val_accuracy: 0.5230\n",
      "Epoch 25/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.7774 - accuracy: 0.7239 - val_loss: 1.0060 - val_accuracy: 0.6590\n",
      "Epoch 26/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.7740 - accuracy: 0.7236 - val_loss: 1.5524 - val_accuracy: 0.5233\n",
      "Epoch 27/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.7713 - accuracy: 0.7236 - val_loss: 1.9905 - val_accuracy: 0.4633\n",
      "Epoch 28/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.7470 - accuracy: 0.7334 - val_loss: 1.0617 - val_accuracy: 0.6593\n",
      "Epoch 29/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.7182 - accuracy: 0.7463 - val_loss: 1.2701 - val_accuracy: 0.6380\n",
      "Epoch 30/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.7282 - accuracy: 0.7407 - val_loss: 0.9704 - val_accuracy: 0.6847\n",
      "Epoch 31/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.7004 - accuracy: 0.7509 - val_loss: 1.5962 - val_accuracy: 0.5897\n",
      "Epoch 32/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.6882 - accuracy: 0.7551 - val_loss: 1.1973 - val_accuracy: 0.6130\n",
      "Epoch 33/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.6715 - accuracy: 0.7647 - val_loss: 1.3858 - val_accuracy: 0.5733\n",
      "Epoch 34/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.6604 - accuracy: 0.7684 - val_loss: 1.2184 - val_accuracy: 0.6427\n",
      "Epoch 35/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.6513 - accuracy: 0.7723 - val_loss: 1.1295 - val_accuracy: 0.6580\n",
      "Epoch 36/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.6401 - accuracy: 0.7753 - val_loss: 2.1693 - val_accuracy: 0.4877\n",
      "Epoch 37/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.6324 - accuracy: 0.7786 - val_loss: 2.7803 - val_accuracy: 0.4503\n",
      "Epoch 38/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.6294 - accuracy: 0.7781 - val_loss: 1.4878 - val_accuracy: 0.5713\n",
      "Epoch 39/40\n",
      "7000/7000 [==============================] - 30s 4ms/sample - loss: 0.6009 - accuracy: 0.7899 - val_loss: 1.5539 - val_accuracy: 0.5800\n",
      "Epoch 40/40\n",
      "7000/7000 [==============================] - 31s 4ms/sample - loss: 0.5895 - accuracy: 0.7941 - val_loss: 1.5813 - val_accuracy: 0.5817\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, targets_train,\n",
    "            batch_size=128,\n",
    "            epochs=40,\n",
    "            verbose=1,\n",
    "            validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
